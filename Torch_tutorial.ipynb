{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VrRGdK95RK2l"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPDiUxiwc4Ji8QP+6OoGAzs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grasht/grashaw_GAN_research_project/blob/main/Torch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tutorial exercise to familiarize oneself with PyTorch. We will load a dataset, define a neural network and train this model."
      ],
      "metadata": {
        "id": "Z7b1ecD-pIYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "WhYQMpKvm5qZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltf5qtEylM7U",
        "outputId": "dcd90f81-417d-4fef-ff24-7994c7af8347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available()) # Checks for GPU access"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import train\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "#Create Data Loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X,y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbAxgEsfmDxk",
        "outputId": "17df1afc-7b8c-4d5b-f420-72bd19e52887"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 111MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 3.52MB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 59.6MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 16.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To define a neural network in PyTorch we must create a class that inherits from nn.Module. Layers are defined in the call to __init__. Operations are moved to the acceleartor if it is available otherwise we use the CPU.\n",
        "\n",
        "Notice we use the `.to` method to explicitly move tensors to the accelerator."
      ],
      "metadata": {
        "id": "HMpHxR7no7wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import ReLU\n",
        "#Set device (check for accelerator)\n",
        "#device = torch.accelerator.current_accelerator().type if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device.\")\n",
        "\n",
        "#Create a class that inherits from nn.Module\n",
        "#Define Model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIviwoExmhZq",
        "outputId": "a8468695-c5f3-4901-a5d2-51649f12afa9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device.\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the loss function, the optimizer, a train function, and a test function that computer accuracy and avg loss."
      ],
      "metadata": {
        "id": "b3tJCuwhuJKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #Compute Prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #Backpropogration\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "JCX5WQvJrvix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing is done in iterations called epochs. The model is learning parameters to ideally make better predicitons. Print the accuracy and loss at each epoch. We want to see it improve."
      ],
      "metadata": {
        "id": "ec1Jdc0guZGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pEZuWCTuYHL",
        "outputId": "9974dfb1-20fd-401b-c097-1b146cd404ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.301360 [   64/60000]\n",
            "loss: 2.289417 [ 6464/60000]\n",
            "loss: 2.267507 [12864/60000]\n",
            "loss: 2.268000 [19264/60000]\n",
            "loss: 2.251094 [25664/60000]\n",
            "loss: 2.215970 [32064/60000]\n",
            "loss: 2.227084 [38464/60000]\n",
            "loss: 2.193202 [44864/60000]\n",
            "loss: 2.184705 [51264/60000]\n",
            "loss: 2.160102 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 46.0%, Avg loss: 2.151273 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.161162 [   64/60000]\n",
            "loss: 2.151790 [ 6464/60000]\n",
            "loss: 2.092659 [12864/60000]\n",
            "loss: 2.115367 [19264/60000]\n",
            "loss: 2.062226 [25664/60000]\n",
            "loss: 1.994939 [32064/60000]\n",
            "loss: 2.027157 [38464/60000]\n",
            "loss: 1.946974 [44864/60000]\n",
            "loss: 1.942590 [51264/60000]\n",
            "loss: 1.876181 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.4%, Avg loss: 1.876970 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.912251 [   64/60000]\n",
            "loss: 1.880088 [ 6464/60000]\n",
            "loss: 1.764233 [12864/60000]\n",
            "loss: 1.807981 [19264/60000]\n",
            "loss: 1.695525 [25664/60000]\n",
            "loss: 1.644672 [32064/60000]\n",
            "loss: 1.659299 [38464/60000]\n",
            "loss: 1.567189 [44864/60000]\n",
            "loss: 1.575564 [51264/60000]\n",
            "loss: 1.470389 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.8%, Avg loss: 1.498673 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.572057 [   64/60000]\n",
            "loss: 1.532967 [ 6464/60000]\n",
            "loss: 1.384824 [12864/60000]\n",
            "loss: 1.456487 [19264/60000]\n",
            "loss: 1.337989 [25664/60000]\n",
            "loss: 1.336864 [32064/60000]\n",
            "loss: 1.340735 [38464/60000]\n",
            "loss: 1.273985 [44864/60000]\n",
            "loss: 1.294853 [51264/60000]\n",
            "loss: 1.198983 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.1%, Avg loss: 1.233191 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.317569 [   64/60000]\n",
            "loss: 1.294013 [ 6464/60000]\n",
            "loss: 1.129347 [12864/60000]\n",
            "loss: 1.237269 [19264/60000]\n",
            "loss: 1.114519 [25664/60000]\n",
            "loss: 1.143459 [32064/60000]\n",
            "loss: 1.156541 [38464/60000]\n",
            "loss: 1.100463 [44864/60000]\n",
            "loss: 1.124781 [51264/60000]\n",
            "loss: 1.050085 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.6%, Avg loss: 1.075292 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and loading models"
      ],
      "metadata": {
        "id": "VrRGdK95RK2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXunrfwbRRpB",
        "outputId": "fb7753f1-8dca-4703-8bfe-39079ed172eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n",
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors\n",
        "\"Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\" - Getting Started with PyTorch (https://docs.pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html).\n",
        "\n",
        "Tensors are like NP ndarrays except they work on GPUs and other hardware. They are also optomized for automatic differentiation."
      ],
      "metadata": {
        "id": "6TIgBN2aR70x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensors can be declared directly from data. Dtype is infered\n",
        "data = [[1,2], [3,4]]\n",
        "x_data = torch.tensor(data)\n",
        "\n",
        "#Or they can be declared from NP arrays\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "\n",
        "#Or from another Tensor\n",
        "x_ones = torch.ones_like(x_data) #retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) #overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEraEQ9jSms8",
        "outputId": "d73265e9-6fc4-4071-d556-393389decb98"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.3993, 0.0536],\n",
            "        [0.9519, 0.1332]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Attributes of a tensor\n",
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\") #Shape\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\") #Datatype\n",
        "print(f\"Device tensor is stored on: {tensor.device}\") #Where they are stored"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEmR078iTmwI",
        "outputId": "1beaa518-e93a-412c-cf2b-2d58d15f68cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are over 1200 tensor operations (https://docs.pytorch.org/docs/stable/torch.html). They can all be run on the CPU and Accelerators (CUDA, MPS, MTIA, XPU).\n",
        "\n",
        "To use an accelerator on Colab:\n",
        "Runtime > Change runtime type > GPU\n",
        "\n",
        "Recall we use `.to` to move tensors to device. We can also check that the device is available `if torch.accelerator.is_available():\n",
        "    tensor = tensor.to(torch.accelerator.current_accelerator())`\n",
        "\n"
      ],
      "metadata": {
        "id": "pQ62gQCpZTfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensors use standard indexing and slicing like NP\n",
        "tensor = torch.ones(4, 4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,1] = 0\n",
        "print(tensor)\n",
        "\n",
        "#cat to join tensors\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)\n",
        "\n",
        "#Arithmetic\n",
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "# ``tensor.T`` returns the transpose of a tensor\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)\n",
        "\n",
        "#Aggregate to one item and convert\n",
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0evGkj8bBnA",
        "outputId": "5c8ecddd-cdec-49a5-d8a5-80659a6ac26c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
            "12.0 <class 'float'>\n"
          ]
        }
      ]
    }
  ]
}